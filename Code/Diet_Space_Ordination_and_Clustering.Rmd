---
output: html_document
---

# Ordination, Clustering, and Fossil & Cryptic Diet Space Projections

This scripts covers a few different sections of the manuscript. First, we use a polychoric PCA to project the extant species with dietary rankings into a multivariate diet space. We then compare the categorical dietary groupings from the [Animal Diversity Web](https://animaldiversity.org/) to see how diet space matches these categories. Then we then use a cluster analysis with the package mclust to see if the clusters returned match the categorical data, and verify these results with an adjusted Rand index. 

The last sections entail projecting the dietary predictions of the "cryptic" and extinct taxa into the diet space generated from the species with data (above), then estimating the nearest neighbors in diet space of these species that lack empirical diet data. 


#### Outputs

- The first output is the mclust cluster analysis results called `Data/Mclust_results.csv`. Then the plot of those data is output as `Plots/Fig_1B_mclust.png`. 

- Next outputs are the cryptic and fossil dietspace nearest neighbor predictions, called 
`Data/Cryptic_Taxa_Nearest_Neighbors.csv` and `Data/Fossil_Taxa_Nearest_Neighbors.csv`.

## Data 

```{r}
pacman::p_load(mclust, polycor, NbClust, tidyverse, ggstar, janitor, here)
here::i_am('Code/Diet_Space_Ordination_and_Clustering.Rmd')
d <- read.delim(here("Data", "Master_Data.txt"))
d2 <- d[,c(3,12:(ncol(d)))]
rownames(d2) <- d$Species
length(which(apply(apply(d2, 2, is.na), 1, sum)>0))
d2<-d2[-which(apply(apply(d2, 2, is.na), 1, sum)>0),]
d3 <- d2[,-1]
nrow(d3)
d3 <- d3+1
```
so that's 105 species total, with 13 missing diets and 92 complete. 

## Polychoric PCA 

Now we need to generate the polychoric correlation matrix. We will use the polychor function in the polycor package to compute pairwise correlations between dietary item codings. 

```{r polychor, cache=T}
poly_mat <- matrix(data=NA, nrow=13, ncol=13)
rownames(poly_mat) <- colnames(poly_mat) <- colnames(d3)
for(i in 1:13) {
  for(j in 1:13) {
    if(i==j){
      tmp =1
    } else{
      tmp = polychor(x=d3[,i], y= d3[,j], ML=TRUE)
    }
     poly_mat[i,j] <- tmp
  } 
}
```


and then we can rotate the diet importance data by performing an eigen decomposition on the matrix 

```{r pca}
es = eigen(poly_mat);
means <-apply(d3, 2, mean)
ones <- as.matrix(rep(1, nrow(d3)))
S<- (as.matrix(d3)-(ones%*%means)) %*%es$vectors
```

S is our matrix of PC scores. We can look at the percent variance explained by each pc by looking at the relative eigen values, the significant pcs by finding those with eigenvalues > 1, and the loadings by getting the correlations of the original variables with the pc axes.

```{r pca_summaries}
# % variance explained
round(es$values/sum(es$values) *100, 2)
# significant pcs
which(es$values>1) 
# loadings
Loadings<-(t(d3) %*% S) / (nrow(d3)-1)
Loadings[,1:5]
```

We can take a quick look at the first 2 PCs wrt to diet from animal diversity web

```{r}
plot(S[,1:2], type="n", bty="n", axes=F, xlab="PC 1 (21%)", ylab= "PC 2 (17%)")
abline(h=0)
abline(v=0)

diets <- as.factor(d2$Discrete)
colors <- RColorBrewer::brewer.pal(6, 'Set2')

filled.hull <- function(d, col) {
  hpts <- chull(d)
  hpts <- c(hpts, hpts[1])
  polygon(d[hpts,1], d[hpts,2], border=col, col=adjustcolor(col, alpha.f = 0.5))
}


for(i in 1:length(levels(diets))) {
  tmp<-which(d2$Discrete== as.character(levels(diets)[i]))
  filled.hull(S[tmp,1:2], col = colors[i])
}

points(S[,1:2], pch=21,bg=colors[as.factor(d2$Discrete)], cex=2)
text(S[,1:2], labels=rownames(d3), cex=0.5, pos=3)
legend("bottomleft", legend=levels(as.factor(d2$Discrete)), pch=21, pt.bg=colors, pt.cex=1.5, bty="n")
```

So clearly there is plenty of overlap between the different groups. We will investigate whether there are more natural groupings based on item importance using clustering. 

## Mclust Clustering 

Clustering of Diet Space using the R package mclust. 

```{r}
# This is the model selection process. G sets the number of possible clusters, default is 1:9
BIC <- mclustBIC(S[,1:13], G = 1:20)
summary(BIC)
```
The model prefers 4 clusters.
```{r}
# Here we add in the model selection results using `x = ` so it doesn't go through that process again
mod1 <- Mclust(S, x = BIC)
summary(mod1)

# Data Wrangle
#Add clusters and discrete diets to S matrix
cls <- as.data.frame(mod1$classification) %>% rename(class = "mod1$classification")
vore <- as.data.frame(d2$Discrete) %>% rename(diet = "d2$Discrete")
S2 <- as.data.frame(S) %>% 
  add_rownames(var = "Species") %>% 
  bind_cols(cls, vore) %>% 
  mutate(class = as.factor(class),
         diet = as.factor(diet))

S2 %>% relocate(class, diet) %>% write_csv( here("Data", "Mclust_results.csv"))
```

### Plot Fig 1B 

```{r}
# Made a second diet results to 
S2 <- read_csv(here("Data", "Mclust_results.csv")) %>% 
  mutate(class = as.factor(class))

colurs <- c("1" = "#31688E", "2" = "#35B779", "3" = "#FDE725", "4" = "#440154")
colurs2 <- c("1" = "#dd8871", "2" = "#51bc27", "3" = "#69efeb", "4" = "#4624b5")
# Make Convex Hulls
hull <- S2 %>% 
  group_by(class) %>% 
  slice(chull(V1, V2))
# Plot
S2  %>% ggplot(aes(x = V1, y = V2)) + 
   
  geom_star(aes(starshape = diet, fill = class), size = 3.5, starstroke = 1) + 
  scale_starshape_manual(c(15, 13, 28, 23, 5, 14)) +
  geom_polygon(aes(color = class, fill = class), data = hull, alpha = 0.35) +
      scale_color_manual(values = colurs) +
    scale_fill_manual(values = colurs) +
  labs(x = "PC 1 (28%)", y = "PC 2 (18%)") +
  guides(color = "none", fill = "none") +
  theme_classic() +
  theme(legend.title = element_blank(), 
        legend.position = c(0.09, 0.87),
        panel.background = element_blank(),
        legend.text=element_text(size=12),
        axis.text.y = element_text(angle = 90),
        panel.border = element_blank())

ggsave(here("Plots", "Fig_1B_mclust.png"), height = 7, width = 8)
ggsave(here("Plots", "Fig_1B_mclust.pdf"), height = 7, width = 8)
```



#### Comparing Clusters to Discrete Categories

We can force classification of 4 clusters, then see how the predictions line up with our discrete categories.
```{r}
# 4 cluster
mod6 <- Mclust(S, G = 4)
#
table(d2$Discrete, mod1$classification)

adjustedRandIndex(d2$Discrete, mod1$classification)
```
Carnivore is split between classes, frugivore and herbivore are in the same, piscivore is well defined. The adjusted Rand Index is .17, with 0 being random and 1 being perfect predictions, so not great. 


## Projecting predicted taxa into the diet space

We'll use the weighted average predictions to project data-deficient and fossil taxa into the polychoric pc space and find the closest neighbors of these taxa.

### Cryptic Nearest Neighbors

```{r}
extant_weighted_av <- read.csv(here("Data", "Extant_Weighted_Predictions_New.csv"), row.names = 1) %>% janitor::clean_names()
cor_mat<-cor(extant_weighted_av)

es = eigen(cor_mat);
means <-apply(extant_weighted_av, 2, mean)
ones <- as.matrix(rep(1, nrow(extant_weighted_av)))
S_new<- (as.matrix(extant_weighted_av)-(ones%*%means)) %*%es$vectors


cryptic <- read.csv(here("Data", "Cryptic_Weighted_Predictions_New.csv"), stringsAsFactors = F, row.names = 1) %>% janitor::clean_names()
cryptic<-cryptic[ ,match(names(means),colnames(cryptic))]

ones <- as.matrix(rep(1, nrow(cryptic)))
S_cryptic<-(as.matrix(cryptic)-(ones%*%means)) %*%es$vectors

get_neighbors <- function(taxon, taxa) {
  distances <- numeric()
  for(i in 1:nrow(taxa)) distances[i] <- dist(rbind(taxon, taxa[i,]), method = "euclidean")
  names(distances) <- rownames(taxa)
  sort(distances)
  
}
cryptic_res <- matrix(data=NA, nrow=nrow(S_cryptic), ncol=5)
for(i in 1:nrow(S_cryptic)) cryptic_res[i,] <- names(get_neighbors(S_cryptic[i,1:5], S_new[,1:5]))[c(1:5)]
rownames(cryptic_res) <- rownames(S_cryptic)
colnames(cryptic_res) <- paste("nearest", 1:5, sep="_")
write.csv(cryptic_res, here("Data", "Cryptic_Taxa_Nearest_Neighbors.csv"))
```

### Fossil Nearest Neighbors


```{r}
fossils <- read.csv(here("Data", "Fossil_Weighted_Predictions_New.csv"), stringsAsFactors = F, row.names = 1) %>% janitor::clean_names()
fossils<-fossils[ ,match(names(means),colnames(fossils))]
ones <- as.matrix(rep(1, nrow(fossils)))
S_fossils<-(as.matrix(fossils)-(ones%*%means)) %*%es$vectors
rownames(fossils)

fossils_res <- matrix(data=NA, nrow=nrow(S_fossils), ncol=5)
for(i in 1:nrow(S_fossils)) fossils_res[i,] <- names(get_neighbors(S_fossils[i,1:5], S_new[,1:5]))[c(1:5)]
rownames(fossils_res) <- rownames(S_fossils)
colnames(fossils_res) <- paste("nearest", 1:5, sep="_")
write.csv(fossils_res, here("Data", "Fossil_Taxa_Nearest_Neighbors.csv"))
```

